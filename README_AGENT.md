# Agentic AI Document Intelligence System
## Production-Grade, Prize-Level Agent for Agentathon 2025

---

## ğŸ¯ What This Is

This is **NOT a chatbot**. This is **NOT a simple RAG app**.

This is a **fully autonomous, multi-step, tool-using agent** with:
- âœ… Visible decision-making
- âœ… Memory and state management
- âœ… Automatic recovery loops
- âœ… Full observability

---

## ğŸ—ï¸ Architecture

### Agent States (LangGraph)

```
PLANNER â†’ EXECUTOR â†’ VALIDATOR â†’ RECOVERY â†’ (Retry or End)
```

1. **Planner**: Analyzes task, creates execution plan
2. **Executor**: Executes plan step-by-step using tools
3. **Validator**: Validates results, decides if recovery needed
4. **Recovery**: Handles failures, retries with backoff

### Tools (Real Python Functions)

The agent dynamically chooses from 10+ tools:
- `preprocess_document` - Extract text from documents
- `classify_sector` - Classify document sector
- `extract_events` - Extract structured events
- `detect_risks` - Detect risks and issues
- `store_events` - Store in database
- `create_embeddings` - Create vector embeddings
- `generate_alerts` - Generate alerts
- `store_alerts` - Store alerts
- `get_timeline` - Get entity timeline
- `generate_insights` - Generate LLM insights

### Memory

- **Short-term**: LangGraph state (in-memory during execution)
- **Long-term**: SQLite + FAISS vector store (persistent)

---

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add:
GROQ_API_KEY=your_groq_key
# OR
GOOGLE_API_KEY=your_gemini_key
LLM_PROVIDER=groq  # or "gemini"
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Run with Docker (Recommended)

```bash
# Build and run
docker-compose up --build

# Or with Docker
docker build -t agentathon-agent .
docker run -p 8000:8000 --env-file .env agentathon-agent
```

### 4. Run Locally

```bash
# Start server
uvicorn main:app --reload

# Server runs on http://localhost:8000
```

---

## ğŸ“¡ API Usage

### Process Document (Agent Mode)

```bash
curl -X POST "http://localhost:8000/process?use_agent=true" \
  -F "files=@document.pdf" \
  -F "entity_id=entity_123"
```

**Response includes full observability:**
```json
{
  "status": "success",
  "agent_mode": true,
  "results": [{
    "file_id": "file_abc123",
    "sector": "healthcare",
    "events": [...],
    "alerts": [...],
    "observability": {
      "execution_log": [
        {"step": "planner", "timestamp": "...", "result": {...}},
        {"step": "executor", "tool": "preprocess_document", ...},
        {"step": "validator", "validation_passed": true, ...}
      ],
      "tools_used": [
        {"tool": "preprocess_document", "success": true, ...},
        {"tool": "extract_events", "success": true, ...}
      ],
      "retry_count": 0,
      "validation_passed": true,
      "recovery_actions": []
    }
  }]
}
```

### Get Observability

```bash
curl "http://localhost:8000/observability/file_abc123"
```

---

## ğŸ” Observability

Every agent execution provides:

1. **Execution Log**: Step-by-step trace
   - Planner decisions
   - Tool calls
   - Validation results
   - Recovery actions

2. **Tool Usage**: All tool calls with:
   - Tool name
   - Success/failure
   - Timestamps
   - Results

3. **Retry Tracking**: 
   - Retry count
   - Recovery actions taken
   - Final outcome

4. **Validation Status**:
   - Validation passed/failed
   - Errors detected
   - Recovery triggers

---

## ğŸ¯ How Autonomy is Achieved

### 1. Planning
Agent creates execution plan based on document type and requirements.

### 2. Execution
Agent executes plan step-by-step, calling tools dynamically.

### 3. Validation
Agent validates each step, checking for errors or missing data.

### 4. Recovery
If validation fails:
- Agent identifies failed steps
- Retries with backoff
- Adjusts strategy if needed
- Fails gracefully after max retries

### 5. No Human Intervention
Once started, agent runs autonomously:
- Makes decisions
- Chooses tools
- Handles errors
- Recovers from failures
- Completes or fails gracefully

---

## ğŸ† For Judges

### 3-Minute Demo Script

1. **Show Agent Architecture** (30s)
   - "This is a LangGraph agent with 4 states: Planner, Executor, Validator, Recovery"

2. **Process a Document** (60s)
   - Upload a document via API
   - Show agent making decisions
   - Show tool calls in real-time
   - Show validation and recovery

3. **Show Observability** (60s)
   - Show execution log
   - Show tool usage
   - Show retry logic
   - Show final result

4. **Explain Autonomy** (30s)
   - "Agent plans, executes, validates, and recovers autonomously"
   - "No human intervention needed once started"

### Key Points to Highlight

âœ… **True Agent**: Not a chatbot, not simple RAG  
âœ… **LangGraph**: Industry-standard orchestration  
âœ… **Tool-Based**: Real Python functions, not just prompts  
âœ… **Observable**: Every decision is logged  
âœ… **Autonomous**: Runs without human intervention  
âœ… **Production-Ready**: Docker, logging, error handling  

---

## ğŸ“ Project Structure

```
agentathon/
â”œâ”€â”€ agent/              # Agent system
â”‚   â”œâ”€â”€ state.py        # Agent state definition
â”‚   â”œâ”€â”€ graph.py        # LangGraph workflow
â”‚   â”œâ”€â”€ nodes.py        # Agent nodes (Planner, Executor, etc.)
â”‚   â”œâ”€â”€ tools.py        # Tool registry
â”‚   â””â”€â”€ orchestrator.py # Main orchestrator
â”œâ”€â”€ modules/            # Sector modules
â”‚   â”œâ”€â”€ healthcare/
â”‚   â”œâ”€â”€ finance/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ main.py             # FastAPI app
â”œâ”€â”€ step*.py            # Pipeline steps
â”œâ”€â”€ Dockerfile          # Production deployment
â”œâ”€â”€ docker-compose.yml  # Local development
â””â”€â”€ requirements.txt    # Dependencies
```

---

## ğŸ”§ Configuration

### LLM Provider

Set `LLM_PROVIDER` in `.env`:
- `groq` - Uses Groq (Llama 3.3 70B)
- `gemini` - Uses Google Gemini 1.5 Pro

### Retry Configuration

In `agent/nodes.py`:
```python
max_retries = 3  # Adjust as needed
```

---

## ğŸš¢ Deployment

### GCP Cloud Run

```bash
# Build and push
gcloud builds submit --tag gcr.io/PROJECT_ID/agentathon-agent

# Deploy
gcloud run deploy agentathon-agent \
  --image gcr.io/PROJECT_ID/agentathon-agent \
  --platform managed \
  --region us-central1 \
  --set-env-vars GROQ_API_KEY=your_key
```

### GCP VM

```bash
# Build Docker image
docker build -t agentathon-agent .

# Run on VM
docker run -d -p 8000:8000 --env-file .env agentathon-agent
```

---

## ğŸ“Š Monitoring

### Health Check

```bash
curl http://localhost:8000/
```

### Observability Endpoint

```bash
curl http://localhost:8000/observability/{file_id}
```

### Structured Logs

All logs are in JSON format for easy parsing:
```json
{
  "timestamp": "2025-01-17T10:00:00",
  "level": "info",
  "event": "agent_step",
  "step": "executor",
  "tool": "extract_events",
  "success": true
}
```

---

## âœ… Non-Negotiable Requirements Met

- âœ… **LangGraph Required**: Full LangGraph implementation
- âœ… **Explicit States**: Planner, Executor, Validator, Recovery
- âœ… **Real Tools**: Python functions, not prompts
- âœ… **Observability**: Step-by-step logs, tool usage, retries
- âœ… **Autonomy**: Plan â†’ Execute â†’ Validate â†’ Retry
- âœ… **Deployment Ready**: Dockerfile, .env support
- âœ… **No Silent Failures**: All errors logged and handled
- âœ… **Explainable**: Every decision is observable

---

## ğŸ“ Learning Resources

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [Agent Patterns](https://langchain-ai.github.io/langgraph/tutorials/)
- [Structured Logging](https://www.structlog.org/)

---

## ğŸ“ License

MIT License - Built for Agentathon 2025

---


